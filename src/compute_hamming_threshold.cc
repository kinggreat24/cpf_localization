#define __STDC_LIMIT_MACROS

// C++ includes
#include <bitset>
#include <vector>
#include <set>
#include <map>
#include <iostream>
#include <iomanip>
#include <fstream>
#include <algorithm>
#include <stdint.h>
#include <string>
#include <algorithm>
#include <climits>
#include <float.h>
#include <cmath>
#include <sstream>
#include <stdio.h>

// includes for classes dealing with SIFT-features
#include "features/SIFT_loader.hh"
#include "features/visual_words_handler.hh"
#include "sfm/parse_bundler.hh"

// stopwatch
#include "timer.hh"

const uint64_t sift_dim = 128;


int main (int argc, char **argv)
{

  if ( argc < 6 )
  {
    std::cout << "_______________________________________________________________________________________________" << std::endl;
    std::cout << " - Usage: compute_hamming_threshold                                                          - " << std::endl;
    std::cout << " - In this code, we set the dimension of hamming based binary signatures as 64               - " << std::endl;
    std::cout << " - Parameters:                                                                               - " << std::endl;
    std::cout << " -  argv[1]: The number of visual words                                                      - " << std::endl;
    std::cout << " -  argv[2]: The detaild visual vocabulary. Each row stores one visual word (as 128 floats)  - " << std::endl;
    std::cout << " -  argv[3]: The visual word assignments of feature descriptors in SfM models                - " << std::endl;
    std::cout << " -  argv[4]: the projection matrix used in hamming embedding                                 - " << std::endl;
    std::cout << " -  argv[5]: output file                                                                     - " << std::endl;
    std::cout << "_______________________________________________________________________________________________" << std::endl;
    return -1;
  }
  // get the parameter
  uint32_t nb_clusters = (uint32_t) atoi( argv[1] );
  std::string cluster_file( argv[2] );
  std::string vw_assignments( argv[3] );
  std::ifstream ifs_projection_matrix(argv[4], std::ios::in);
  if (!ifs_projection_matrix.is_open()) {
    std::cerr << "ERROR: Cannot read the projection "
              << "matrix from " << argv[4] << std::endl;
    return -1;
  }
  std::ofstream ofs(argv[5], std::ios::out);
  Eigen::Matrix<float, 64, 128, Eigen::RowMajor> projection_matrix;
  // Loads the projection matrix.
  for (int i = 0; i < 64; ++i) {
    for (int j = 0; j < 128; ++j) {
      ifs_projection_matrix >> projection_matrix(i, j);
    }
  }
  ifs_projection_matrix.close();

  // load the assignments for the visual words
  std::cout << "* Loading and parsing the assignments ... " << std::endl;
  // store the 3D positions of the 3D points
  std::vector< Eigen::Vector3f > points3D;
  // store the descriptors in a vector simply by concatenating their entries
  // depending on the mode, either unsigned char entries or floating point entries are used
  std::vector< unsigned char > all_descriptors;
  // for every visual word, store a vector of (3D point id, descriptor id) pairs, where the 3D point id
  // is the index of the 3D point in points3D and the descriptor id is the position of the first entry of the corresponding
  // descriptor in all_descriptors / all_descriptors_float
  std::vector< std::vector< std::pair< uint32_t, uint32_t > > > vw_points_descriptors(nb_clusters);
  // store per visual word the number of (point, descriptor) pairs store in it
  std::vector< uint32_t > nb_points_per_vw(nb_clusters, 0);

  // number of non-empty visual words, the number of 3D points and the total number of descriptors
  uint32_t nb_non_empty_vw, nb_3D_points, nb_descriptors;

  for ( uint32_t i = 0; i < nb_clusters; ++i )
    vw_points_descriptors[i].clear();
  // load the assignments from a file generated by compute_desc_assignments
  {
    std::ifstream ifs( vw_assignments.c_str(), std::ios::in | std::ios::binary  );
    if ( !ifs )
    {
      std::cerr << " ERROR: Cannot read the visual word assignments " << vw_assignments << std::endl;
      return -1;
    }
    uint32_t nb_clusts;
    ifs.read(( char* ) &nb_3D_points, sizeof( uint32_t ) );
    ifs.read(( char* ) &nb_clusts, sizeof( uint32_t ) );
    ifs.read(( char* ) &nb_non_empty_vw, sizeof( uint32_t ) );
    ifs.read(( char* ) &nb_descriptors, sizeof( uint32_t ) );

    if ( nb_clusts != nb_clusters )
      std::cerr << " WARNING: Number of clusters differs! " << nb_clusts << " " << nb_clusters << std::endl;

    std::cout << "  Number of non-empty clusters: " << nb_non_empty_vw << " number of points : " << nb_3D_points << " number of descriptors: " << nb_descriptors << std::endl;

    // read the 3D points and their visibility polygons
    points3D.resize(nb_3D_points);
    all_descriptors.resize(uint64_t(nb_descriptors) * 128, -1 );

    // load the points
    float *point_data = new float[3];
    for ( uint32_t i = 0; i < nb_3D_points; ++i )
    {
      ifs.read(( char* ) point_data, 3 * sizeof( float ) );
      for ( int j = 0; j < 3; ++j )
        points3D[i][j] = point_data[j];

      //std::cout << points3D[i][0] << " " << points3D[i][1] << " " << points3D[i][2] << std::endl;
    }
    delete [] point_data;

    // load the descriptors
    uint64_t index = 0;
    for ( uint32_t i = 0; i < nb_descriptors; ++i, index += sift_dim )
    {
      // std::cout << i << std::endl;
      for ( uint64_t j = 0; j < sift_dim; ++j )
      {
          ifs.read(( char* ) &all_descriptors[index + j], sizeof( unsigned char ) );
      }
    }

    std::cout << "done loading descriptors" << std::endl;

    // now we load the assignments of the pairs (point_id, descriptor_id) to the visual words
    for ( uint32_t i = 0; i < nb_clusters; ++i )
    {
      uint32_t id, nb_pairs;
      ifs.read(( char* ) &id, sizeof( uint32_t ) );
      ifs.read(( char* ) &nb_pairs, sizeof( uint32_t ) );
      vw_points_descriptors[id].resize( nb_pairs );
      nb_points_per_vw[id] = nb_pairs;
      // ofs << nb_pairs << std::endl;
      for ( uint32_t j = 0; j < nb_pairs; ++j )
      {
        ifs.read(( char* ) &vw_points_descriptors[id][j].first, sizeof( uint32_t ) );
        ifs.read(( char* ) &vw_points_descriptors[id][j].second, sizeof( uint32_t ) );
      }
    }
    ifs.close();
    std::cout << "  done loading and parsing the assignments " << std::endl;
  }

  std::cout << "there are total " << all_descriptors.size() / 128 << " features" << std::endl;

  Eigen::Matrix<float, 64, Eigen::Dynamic> he_thresholds;
  //this should be the same size of visual clusters size.
  he_thresholds.resize(64, nb_clusters);
  //now project the descriptors in each visual word into hamming space.
  //this is the vector to store all projection results for each visual word

  std::cout << "finish setting entries per word" << std::endl;

  for (int i = 0; i < nb_clusters; ++i) {
    std::vector<std::vector<std::vector<float> > > entries_per_word(1);
    entries_per_word[0].resize(64);
      for (int j = 0; j < 64; ++j) entries_per_word[0][j].clear();
    

    int in_word_nb =  nb_points_per_vw[i];
    if (in_word_nb == 0) {
      std::cout << " WARNING: FOUND EMPTY WORD " << i << std::endl;
      he_thresholds.col(i) = Eigen::Matrix<float, 64, 1>::Zero();
    }
    else {
      for (int j = 0; j < in_word_nb; j++)
      {
        //std::cout << i << " " << in_word_nb << std::endl;
        Eigen::Matrix<float, 128, 1> sift;
        //assign the corresponding sift feature
        uint64_t cur_desc = vw_points_descriptors[i][j].second;
        for (int k = 0; k < 128; k++)
        {
          uint64_t cur_feature_index = cur_desc * 128 + uint64_t(k);
          //std::cout << float(all_descriptors[cur_feature_index]) << std::endl;
          sift(k, 0) = all_descriptors[cur_feature_index];
        }
        //do the hamming projection
        Eigen::Matrix<float, 64, 1> proj_sift = projection_matrix * sift;
        for (int k = 0; k < 64; ++k) {
          entries_per_word[0][k].push_back(proj_sift[k]);
        }
      }
      //compute the thresholds
      const int median_element = in_word_nb / 2;
      for (int k = 0; k < 64; ++k) {
        std::nth_element(entries_per_word[0][k].begin(),
                         entries_per_word[0][k].begin() + median_element,
                         entries_per_word[0][k].end());
        he_thresholds(k, i) = entries_per_word[0][k][median_element];
      }

    }
  }
  std::cout << "finish getting the hamming thresholds" << std::endl;

  //after performing thresholding. compute the hamming embedding for each descriptors in database.
  //for each visual word, encode the pair of binary descriptors and point index.
  std::vector <uint64_t> all_binary_descriptors;
  all_binary_descriptors.resize(nb_descriptors);
  for (int i = 0; i < nb_clusters; ++i) {
    int in_word_nb =  nb_points_per_vw[i];
    if (in_word_nb == 0) {
      // std::cout << " Do not compute the binary descriptors " << i << std::endl;
    }
    else {
      for (int j = 0; j < in_word_nb; j++)
      {
        Eigen::Matrix<float, 128, 1> sift;
        //assign the corresponding sift feature
        uint64_t cur_desc = vw_points_descriptors[i][j].second;
        for (int k = 0; k < 128; k++)
        {
          uint64_t cur_feature_index = cur_desc * 128 + uint64_t(k);
          sift(k, 0) = all_descriptors[cur_feature_index];
        }
        //do the hamming projection
        Eigen::Matrix<float, 64, 1> proj_sift = projection_matrix * sift;
        //for each dimension, calculate the binary with median hamming thresholds
        std::bitset<64> binary_descriptor;
        for (int k = 0 ; k < 64; k++)
        {
          binary_descriptor[k] = proj_sift[k] > he_thresholds(k, i);
        }
        all_binary_descriptors[cur_desc] = binary_descriptor.to_ulong();
      }
    }
  }

  std::cout << "finish transferring to binary" << std::endl;

  if (!ofs.is_open()) {
    std::cerr << "ERROR: Cannot write to " << argv[5] << std::endl;
    return -1;
  }

  ofs << nb_3D_points << " " << nb_clusters << " " << nb_non_empty_vw << " " << nb_descriptors << std::endl;
  ofs << nb_clusters << " 128 64" << std::endl;
  for (int i = 0; i < nb_clusters; ++i) {
    for (int j = 0; j < 64; ++j) {
      ofs << std::setprecision(16) << he_thresholds(j, i) << " ";
    }
    ofs << std::endl;
  }

  std::cout << "Finish writting the hamming thresholds" << std::endl;
  for (int i = 0; i < 64; ++i) {
    for (int j = 0; j < 128; ++j) {
      ofs << std::setprecision(16) << projection_matrix(i, j) << " ";
    }
    ofs << std::endl;
  }
  std::cout << "Finish writting the projection matrix" << std::endl;


  //write the binary descriptors
  for (int i = 0; i < all_binary_descriptors.size(); i++)
  {
    ofs << all_binary_descriptors[i] << std::endl;
  }
  all_binary_descriptors.clear();
  all_descriptors.clear();
  std::cout << "Finish writting the binary descriptors" << std::endl;

  //write the assignments.
  for (int i = 0; i < nb_clusters; ++i) {
    ofs << i << " " << nb_points_per_vw[i] << std::endl;
    for (int j = 0; j < nb_points_per_vw[i]; j++)
    {
      ofs << vw_points_descriptors[i][j].first << " " << vw_points_descriptors[i][j].second << " ";
    }
    ofs << std::endl;
  }
  ofs.close();
  return 0;
}

